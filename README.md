# An√°lisis y Predicci√≥n de Enfermedades Cardiovasculares mediante Agrupaci√≥n No Supervisada

Este proyecto de Google Colab explora la aplicaci√≥n de t√©cnicas de clustering no supervisado, K-Means y Agrupaci√≥n Jer√°rquica, para analizar y predecir el riesgo de enfermedades cardiovasculares. El objetivo principal es identificar patrones en un conjunto de datos m√©dicos y agrupar a los pacientes en categor√≠as de 'Sano' o 'Enfermo' bas√°ndose √∫nicamente en las caracter√≠sticas de los datos, sin etiquetas predefinidas durante el entrenamiento.

## üìä Dataset

El an√°lisis se basa en el dataset de Enfermedades Cardiovasculares (`Cardiovascular_Disease_Dataset.csv`), cargado directamente desde un repositorio de GitHub. Este dataset contiene diversas m√©tricas de salud de pacientes, incluyendo:

*   `age`: Edad
*   `gender`: G√©nero (0: Femenino, 1: Masculino)
*   `chestpain`: Tipo de dolor de pecho
*   `restingBP`: Presi√≥n arterial en reposo
*   `serumcholestrol`: Colesterol s√©rico
*   `fastingbloodsugar`: Az√∫car en sangre en ayunas
*   `restingrelectro`: Resultados electrocardiogr√°ficos en reposo
*   `maxheartrate`: Frecuencia card√≠aca m√°xima alcanzada
*   `exerciseangia`: Angina inducida por ejercicio
*   `oldpeak`: Depresi√≥n del ST inducida por el ejercicio
*   `slope`: La pendiente del segmento ST pico del ejercicio
*   `noofmajorvessels`: N√∫mero de vasos principales coloreados por fluoroscopia
*   `target`: Variable objetivo (0: Sano, 1: Enfermo) - **Utilizada solo para evaluaci√≥n, no para el entrenamiento de los modelos no supervisados**.

## üöÄ Metodolog√≠a

### 1. Preprocesamiento de Datos

Antes de aplicar los algoritmos de clustering, los datos fueron preprocesados:

*   **Divisi√≥n:** El dataset se dividi√≥ en conjuntos de entrenamiento (80%) y prueba (20%).
*   **Escalado:** Las caracter√≠sticas num√©ricas se estandarizaron utilizando `StandardScaler` para asegurar que todas las variables contribuyan de manera equitativa a la formaci√≥n de cl√∫steres, evitando que caracter√≠sticas con rangos de valores m√°s amplios dominen la distancia euclidiana.

### 2. Agrupaci√≥n K-Means

K-Means es un algoritmo de clustering iterativo que busca particionar `n` observaciones en `k` cl√∫steres. Se utiliz√≥ con `n_clusters=2` para alinearlo con las dos categor√≠as (Sano/Enfermo) del problema.

*   **Entrenamiento:** El modelo se entren√≥ con el conjunto de entrenamiento escalado.
*   **Evaluaci√≥n:** Se predijeron las etiquetas de los cl√∫steres para el conjunto de prueba. Para evaluar la precisi√≥n de este modelo no supervisado, se realiz√≥ un **mapeo** de las etiquetas de cl√∫ster obtenidas a las etiquetas verdaderas del dataset (0 o 1) utilizando la clase m√°s frecuente dentro de cada cl√∫ster. Esto permiti√≥ generar una **matriz de confusi√≥n** y un **reporte de clasificaci√≥n**.
*   **Visualizaci√≥n:** Se aplic√≥ **An√°lisis de Componentes Principales (PCA)** para reducir la dimensionalidad de los datos a 2 componentes, permitiendo la visualizaci√≥n de los cl√∫steres y sus centroides en un gr√°fico de dispersi√≥n.
*   **Predicci√≥n para Paciente Nuevo:** Se implement√≥ una funci√≥n para clasificar un nuevo paciente, escalando sus datos y utilizando el modelo K-Means entrenado para asignarlo a uno de los dos cl√∫steres.

### 3. Agrupaci√≥n Jer√°rquica (Agglomerative Clustering)

La Agrupaci√≥n Jer√°rquica construye una jerarqu√≠a de cl√∫steres. En este proyecto, se utiliz√≥ el enfoque aglomerativo (`AgglomerativeClustering`), que comienza con cada punto como un cl√∫ster individual y los fusiona iterativamente.

*   **Entrenamiento:** El modelo se ajust√≥ al conjunto de entrenamiento.
*   **Dendrograma:** Se gener√≥ un dendrograma para visualizar la estructura jer√°rquica de los cl√∫steres y las distancias de fusi√≥n entre ellos.
*   **Evaluaci√≥n:** Similar a K-Means, se mapearon las etiquetas de cl√∫ster a las etiquetas verdaderas para evaluar el rendimiento mediante una **matriz de confusi√≥n** y un **reporte de clasificaci√≥n**.
*   **Predicci√≥n para Paciente Nuevo:** Dado que `AgglomerativeClustering` no tiene un m√©todo `predict` directo para nuevas muestras, se aproxim√≥ la clasificaci√≥n de un nuevo paciente calculando la distancia a los centroides de los cl√∫steres formados y asign√°ndolo al m√°s cercano.

## üìà Resultados y Comparaci√≥n de Modelos

Se realiz√≥ una comparaci√≥n detallada del rendimiento de ambos modelos en t√©rminos de precisi√≥n, tiempo de entrenamiento y tiempo de predicci√≥n (tanto en lotes como para un paciente individual).

| Modelo                                | Tiempo Entrenamiento (s) | Tiempo Predicci√≥n (Batch) (s) | Tiempo Predicci√≥n (Paciente Nuevo) (s) | Precisi√≥n (%) |
| :------------------------------------ | :----------------------- | :---------------------------- | :------------------------------------- | :------------ |
| K-Means                               | 0.0223                   | 0.0097                        | 0.0033                                 | 94.57         |
| Agrupaci√≥n Jer√°rquica                 | 0.1804                   | 0.0313                        | 0.0011                                 | 89.26         |

Los resultados se visualizan mediante gr√°ficos de barras comparativos para facilitar la interpretaci√≥n.

## ‚úÖ Conclusi√≥n

El an√°lisis concluye que el modelo **K-Means** demostr√≥ ser la opci√≥n m√°s robusta y eficiente para la tarea de diagn√≥stico de enfermedades cardiovasculares con los datos actuales. Ofreci√≥ la **mayor precisi√≥n (94.57%)** y un **tiempo de predicci√≥n para pacientes individuales muy r√°pido**, lo que lo hace ideal para aplicaciones en tiempo real.

Aunque la Agrupaci√≥n Jer√°rquica proporcion√≥ una visi√≥n estructural interesante y un tiempo de predicci√≥n de paciente nuevo muy bajo, su precisi√≥n fue ligeramente inferior (89.26%), y su aplicaci√≥n pr√°ctica para predicciones individuales es menos directa. Este estudio establece una base s√≥lida para futuros trabajos, que podr√≠an incluir la exploraci√≥n de otros algoritmos, la incorporaci√≥n de m√°s datos o la transici√≥n a t√©cnicas de aprendizaje supervisado para afinar a√∫n m√°s las predicciones.
